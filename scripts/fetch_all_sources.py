#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
TÃ¼m SaÄŸlÄ±k Kurumu Veri KaynaklarÄ±nÄ± BirleÅŸtiren Ana ModÃ¼l

Bu modÃ¼l, tÃ¼m farklÄ± kaynaklardan saÄŸlÄ±k kurumu verilerini Ã§eker,
mÃ¼kerrer kayÄ±tlarÄ± birleÅŸtirir ve nihai veritabanÄ±nÄ± oluÅŸturur.

Author: TURSAKUR Team
Version: 1.0.0
Date: 2025-01-14
"""

import asyncio
import json
import logging
import os
import subprocess
import sys
from datetime import datetime
from typing import Dict, List
import concurrent.futures

# Logging konfigÃ¼rasyonu
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('logs/fetch_all_sources.log', encoding='utf-8'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

class HealthDataAggregator:
    """SaÄŸlÄ±k veri toplama ve birleÅŸtirme sÄ±nÄ±fÄ±"""
    
    def __init__(self):
        self.sources = {
            'saglik_bakanligi': 'scripts/fetch_saglik_bakanligi_data.py',
            'ozel_hastaneler': 'scripts/fetch_ozel_hastaneler_data.py',
            'universite_hastaneleri': 'scripts/fetch_universite_hastaneleri.py',
            'trhastane_universite': 'scripts/fetch_trhastane_universite.py',
            'kapsamli_universite_hastane': 'scripts/fetch_kapsamli_universite_hastane.py',
            'il_saglik_mudurlukeri': 'scripts/fetch_il_saglik_mudurlukeri.py'
        }
        
        self.output_files = {
            'saglik_bakanligi': 'data/raw/saglik_bakanligi_tesisleri.json',
            'ozel_hastaneler': 'data/raw/ozel_hastaneler.json',
            'universite_hastaneleri': 'data/raw/universite_hastaneleri.json',
            'trhastane_universite': 'data/raw/trhastane_universite_hastaneleri.json',
            'kapsamli_universite_hastane': 'data/raw/kapsamli_universite_hastane_iliskileri.json',
            'il_saglik_mudurlukeri': 'data/raw/il_saglik_mudurlukeri.json'
        }
        
        self.results = {}
    
    def run_script(self, script_name: str, script_path: str) -> Dict:
        """Tek bir script'i Ã§alÄ±ÅŸtÄ±r"""
        logger.info(f"{script_name} script'i Ã§alÄ±ÅŸtÄ±rÄ±lÄ±yor: {script_path}")
        
        try:
            # Python script'ini Ã§alÄ±ÅŸtÄ±r
            result = subprocess.run(
                [sys.executable, script_path],
                capture_output=True,
                text=True,
                encoding='utf-8',
                timeout=1800  # 30 dakika timeout
            )
            
            if result.returncode == 0:
                logger.info(f"{script_name} baÅŸarÄ±yla tamamlandÄ±")
                
                # Ã‡Ä±ktÄ± dosyasÄ±nÄ± kontrol et
                output_file = self.output_files.get(script_name)
                if output_file and os.path.exists(output_file):
                    with open(output_file, 'r', encoding='utf-8') as f:
                        data = json.load(f)
                    
                    return {
                        'status': 'success',
                        'records': len(data),
                        'file': output_file,
                        'stdout': result.stdout,
                        'stderr': result.stderr
                    }
                else:
                    return {
                        'status': 'success_no_output',
                        'records': 0,
                        'file': None,
                        'stdout': result.stdout,
                        'stderr': result.stderr
                    }
            else:
                logger.error(f"{script_name} hata ile sonlandÄ±: {result.stderr}")
                return {
                    'status': 'error',
                    'records': 0,
                    'file': None,
                    'stdout': result.stdout,
                    'stderr': result.stderr
                }
                
        except subprocess.TimeoutExpired:
            logger.error(f"{script_name} timeout ile sonlandÄ±")
            return {
                'status': 'timeout',
                'records': 0,
                'file': None,
                'stdout': '',
                'stderr': 'Script timeout ile sonlandÄ±'
            }
        except Exception as e:
            logger.error(f"{script_name} beklenmeyen hata: {e}")
            return {
                'status': 'exception',
                'records': 0,
                'file': None,
                'stdout': '',
                'stderr': str(e)
            }
    
    def run_all_sources_parallel(self) -> Dict:
        """TÃ¼m kaynaklarÄ± paralel olarak Ã§alÄ±ÅŸtÄ±r"""
        logger.info("TÃ¼m veri kaynaklarÄ± paralel olarak Ã§alÄ±ÅŸtÄ±rÄ±lÄ±yor...")
        
        # Dizinleri oluÅŸtur
        os.makedirs('data/raw', exist_ok=True)
        os.makedirs('logs', exist_ok=True)
        
        results = {}
        
        with concurrent.futures.ThreadPoolExecutor(max_workers=2) as executor:
            # Future'larÄ± baÅŸlat
            future_to_source = {
                executor.submit(self.run_script, source_name, script_path): source_name
                for source_name, script_path in self.sources.items()
                if os.path.exists(script_path)
            }
            
            # SonuÃ§larÄ± topla
            for future in concurrent.futures.as_completed(future_to_source):
                source_name = future_to_source[future]
                try:
                    result = future.result()
                    results[source_name] = result
                    logger.info(f"{source_name} tamamlandÄ±: {result['records']} kayÄ±t")
                except Exception as e:
                    logger.error(f"{source_name} exception: {e}")
                    results[source_name] = {
                        'status': 'exception',
                        'records': 0,
                        'file': None,
                        'stdout': '',
                        'stderr': str(e)
                    }
        
        return results
    
    def run_all_sources_sequential(self) -> Dict:
        """TÃ¼m kaynaklarÄ± sÄ±ralÄ± olarak Ã§alÄ±ÅŸtÄ±r"""
        logger.info("TÃ¼m veri kaynaklarÄ± sÄ±ralÄ± olarak Ã§alÄ±ÅŸtÄ±rÄ±lÄ±yor...")
        
        # Dizinleri oluÅŸtur
        os.makedirs('data/raw', exist_ok=True)
        os.makedirs('logs', exist_ok=True)
        
        results = {}
        
        for source_name, script_path in self.sources.items():
            if os.path.exists(script_path):
                result = self.run_script(source_name, script_path)
                results[source_name] = result
                logger.info(f"{source_name} tamamlandÄ±: {result['records']} kayÄ±t")
            else:
                logger.warning(f"Script bulunamadÄ±: {script_path}")
                results[source_name] = {
                    'status': 'not_found',
                    'records': 0,
                    'file': None,
                    'stdout': '',
                    'stderr': f'Script bulunamadÄ±: {script_path}'
                }
        
        return results
    
    def merge_duplicates(self) -> Dict:
        """MÃ¼kerrer kayÄ±tlarÄ± birleÅŸtir"""
        logger.info("MÃ¼kerrer kayÄ±tlarÄ± birleÅŸtiriliyor...")
        
        merge_script = 'scripts/merge_duplicate_records.py'
        
        if not os.path.exists(merge_script):
            logger.error(f"BirleÅŸtirme script'i bulunamadÄ±: {merge_script}")
            return {
                'status': 'error',
                'message': 'BirleÅŸtirme script\'i bulunamadÄ±'
            }
        
        try:
            result = subprocess.run(
                [sys.executable, merge_script],
                capture_output=True,
                text=True,
                encoding='utf-8',
                timeout=600  # 10 dakika timeout
            )
            
            if result.returncode == 0:
                logger.info("MÃ¼kerrer kayÄ±tlar baÅŸarÄ±yla birleÅŸtirildi")
                
                # BirleÅŸtirilmiÅŸ dosyayÄ± kontrol et
                merged_file = 'data/turkiye_saglik_kuruluslari_merged.json'
                if os.path.exists(merged_file):
                    with open(merged_file, 'r', encoding='utf-8') as f:
                        data = json.load(f)
                    
                    return {
                        'status': 'success',
                        'records': len(data),
                        'file': merged_file,
                        'stdout': result.stdout,
                        'stderr': result.stderr
                    }
                else:
                    return {
                        'status': 'success_no_output',
                        'records': 0,
                        'file': None,
                        'stdout': result.stdout,
                        'stderr': result.stderr
                    }
            else:
                logger.error(f"BirleÅŸtirme hatasÄ±: {result.stderr}")
                return {
                    'status': 'error',
                    'records': 0,
                    'file': None,
                    'stdout': result.stdout,
                    'stderr': result.stderr
                }
                
        except Exception as e:
            logger.error(f"BirleÅŸtirme exception: {e}")
            return {
                'status': 'exception',
                'records': 0,
                'file': None,
                'stdout': '',
                'stderr': str(e)
            }
    
    def finalize_database(self) -> Dict:
        """Nihai veritabanÄ±nÄ± oluÅŸtur"""
        logger.info("Nihai veritabanÄ± oluÅŸturuluyor...")
        
        process_script = 'scripts/process_data.py'
        
        if not os.path.exists(process_script):
            logger.error(f"Veri iÅŸleme script'i bulunamadÄ±: {process_script}")
            return {
                'status': 'error',
                'message': 'Veri iÅŸleme script\'i bulunamadÄ±'
            }
        
        try:
            result = subprocess.run(
                [sys.executable, process_script],
                capture_output=True,
                text=True,
                encoding='utf-8',
                timeout=300  # 5 dakika timeout
            )
            
            if result.returncode == 0:
                logger.info("Nihai veritabanÄ± baÅŸarÄ±yla oluÅŸturuldu")
                
                # Final dosyayÄ± kontrol et
                final_file = 'data/turkiye_saglik_kuruluslari.json'
                if os.path.exists(final_file):
                    with open(final_file, 'r', encoding='utf-8') as f:
                        data = json.load(f)
                    
                    return {
                        'status': 'success',
                        'records': len(data),
                        'file': final_file,
                        'stdout': result.stdout,
                        'stderr': result.stderr
                    }
                else:
                    return {
                        'status': 'success_no_output',
                        'records': 0,
                        'file': None,
                        'stdout': result.stdout,
                        'stderr': result.stderr
                    }
            else:
                logger.error(f"Veri iÅŸleme hatasÄ±: {result.stderr}")
                return {
                    'status': 'error',
                    'records': 0,
                    'file': None,
                    'stdout': result.stdout,
                    'stderr': result.stderr
                }
                
        except Exception as e:
            logger.error(f"Veri iÅŸleme exception: {e}")
            return {
                'status': 'exception',
                'records': 0,
                'file': None,
                'stdout': '',
                'stderr': str(e)
            }
    
    def generate_summary_report(self, source_results: Dict, merge_result: Dict, final_result: Dict) -> str:
        """Ã–zet rapor oluÅŸtur"""
        report = f"""
=== TURSAKUR VERÄ° TOPLAMA VE BÄ°RLEÅTÄ°RME RAPORU ===
Tarih: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}

ğŸ“Š KAYNAK BAZLI VERÄ° TOPLAMA SONUÃ‡LARI:
"""
        
        total_source_records = 0
        successful_sources = 0
        
        for source_name, result in source_results.items():
            status_icon = "âœ…" if result['status'] == 'success' else "âŒ"
            report += f"{status_icon} {source_name.replace('_', ' ').title()}: {result['records']} kayÄ±t\n"
            
            if result['status'] == 'success':
                total_source_records += result['records']
                successful_sources += 1
            
            if result['stderr']:
                report += f"   âš ï¸  UyarÄ±: {result['stderr'][:100]}...\n"
        
        report += f"\nToplam ham kayÄ±t: {total_source_records}\n"
        report += f"BaÅŸarÄ±lÄ± kaynak sayÄ±sÄ±: {successful_sources}/{len(source_results)}\n"
        
        # BirleÅŸtirme sonuÃ§larÄ±
        report += f"\nğŸ”„ MÃœKERRER KAYIT BÄ°RLEÅTÄ°RME:\n"
        if merge_result['status'] == 'success':
            report += f"âœ… BirleÅŸtirme baÅŸarÄ±lÄ±: {merge_result['records']} benzersiz kayÄ±t\n"
            if total_source_records > 0:
                dedup_rate = ((total_source_records - merge_result['records']) / total_source_records) * 100
                report += f"ğŸ“‰ MÃ¼kerrer kayÄ±t oranÄ±: {dedup_rate:.1f}%\n"
        else:
            report += f"âŒ BirleÅŸtirme hatasÄ±: {merge_result.get('stderr', 'Bilinmeyen hata')}\n"
        
        # Final sonuÃ§lar
        report += f"\nğŸ¯ FÄ°NAL VERÄ°TABANI:\n"
        if final_result['status'] == 'success':
            report += f"âœ… Nihai veritabanÄ± oluÅŸturuldu: {final_result['records']} kayÄ±t\n"
            report += f"ğŸ“ Dosya: {final_result['file']}\n"
        else:
            report += f"âŒ Nihai veritabanÄ± hatasÄ±: {final_result.get('stderr', 'Bilinmeyen hata')}\n"
        
        # Performans Ã¶zeti
        report += f"\nğŸ“ˆ PERFORMANS Ã–ZETÄ°:\n"
        report += f"Ham veri â†’ Benzersiz: {total_source_records} â†’ {merge_result.get('records', 0)}\n"
        report += f"Benzersiz â†’ Final: {merge_result.get('records', 0)} â†’ {final_result.get('records', 0)}\n"
        
        if final_result.get('records', 0) > 0:
            report += f"Veri kalitesi: {(final_result['records'] / max(total_source_records, 1)) * 100:.1f}% tutarlÄ±lÄ±k\n"
        
        report += f"\nâ±ï¸  Ä°ÅŸlem tamamlandÄ±: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n"
        
        return report

def main():
    """Ana fonksiyon"""
    try:
        logger.info("TURSAKUR kapsamlÄ± veri toplama iÅŸlemi baÅŸlatÄ±lÄ±yor...")
        
        aggregator = HealthDataAggregator()
        
        # 1. TÃ¼m kaynaklarÄ± Ã§alÄ±ÅŸtÄ±r
        print("ğŸ“¡ Veri kaynaklarÄ± Ã§alÄ±ÅŸtÄ±rÄ±lÄ±yor...")
        source_results = aggregator.run_all_sources_sequential()  # Stable iÃ§in sequential
        
        # 2. MÃ¼kerrer kayÄ±tlarÄ± birleÅŸtir
        print("ğŸ”„ MÃ¼kerrer kayÄ±tlar birleÅŸtiriliyor...")
        merge_result = aggregator.merge_duplicates()
        
        # 3. Nihai veritabanÄ±nÄ± oluÅŸtur
        print("ğŸ¯ Nihai veritabanÄ± oluÅŸturuluyor...")
        final_result = aggregator.finalize_database()
        
        # 4. Rapor oluÅŸtur
        report = aggregator.generate_summary_report(source_results, merge_result, final_result)
        print(report)
        
        # Raporu dosyaya kaydet
        with open('logs/aggregation_report.txt', 'w', encoding='utf-8') as f:
            f.write(report)
        
        # Genel baÅŸarÄ± kontrolÃ¼
        success_count = sum(1 for result in source_results.values() if result['status'] == 'success')
        
        if (success_count >= len(source_results) // 2 and  # En az yarÄ±sÄ± baÅŸarÄ±lÄ±
            merge_result['status'] == 'success' and
            final_result['status'] == 'success'):
            logger.info("KapsamlÄ± veri toplama iÅŸlemi baÅŸarÄ±yla tamamlandÄ±!")
            return 0
        else:
            logger.error("Veri toplama iÅŸleminde kritik hatalar oluÅŸtu!")
            return 1
            
    except Exception as e:
        logger.error(f"Ana fonksiyon kritik hatasÄ±: {e}")
        return 1

if __name__ == "__main__":
    exit(main())
