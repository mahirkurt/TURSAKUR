#!/usr/bin/env python3
"""
TURSAKUR 2.0 - Ana Veri Toplama Orchestrator
==========================================

TÃ¼m veri kaynaklarÄ±nÄ± koordine eden ana script.
Veri.md'de belirtilen ETL pipeline'Ä±nÄ± Ã§alÄ±ÅŸtÄ±rÄ±r.

Ã‡alÄ±ÅŸma SÄ±rasÄ±:
1. Tier 1 kaynaklarÄ± (en yÃ¼ksek Ã¶ncelik)
2. Tier 2 kaynaklarÄ± (doÄŸrulama ve zenginleÅŸtirme)  
3. Tier 3 kaynaklarÄ± (keÅŸif ve Ã§apraz referans)
4. Veri iÅŸleme ve birleÅŸtirme
5. Supabase'e yÃ¼kleme
"""

import sys
import json
import logging
import subprocess
from datetime import datetime, timezone
from pathlib import Path
from typing import Dict, List, Optional
import time

class DataPipelineOrchestrator:
    """TURSAKUR veri toplama pipeline'Ä±nÄ± yÃ¶netir"""
    
    def __init__(self):
        self.scripts_dir = Path(__file__).parent
        self.data_dir = self.scripts_dir.parent / "data"
        self.raw_data_dir = self.data_dir / "raw"
        self.processed_data_dir = self.data_dir / "processed"
        
        # Create directories
        self.raw_data_dir.mkdir(parents=True, exist_ok=True)
        self.processed_data_dir.mkdir(parents=True, exist_ok=True)
        
        # Logging setup
        log_file = self.data_dir / "pipeline.log"
        logging.basicConfig(
            level=logging.INFO,
            format='%(asctime)s - %(levelname)s - %(message)s',
            handlers=[
                logging.FileHandler(log_file),
                logging.StreamHandler(sys.stdout)
            ]
        )
        self.logger = logging.getLogger(__name__)
        
        # Veri kaynaklarÄ±nÄ±n yapÄ±landÄ±rmasÄ±
        self.data_sources = {
            'tier1': [
                {
                    'name': 'SaÄŸlÄ±k BakanlÄ±ÄŸÄ±',
                    'script': 'fetch_saglik_bakanligi_data.py',
                    'description': 'KHGM, SBSGM, YHGM ve Ä°l SaÄŸlÄ±k MÃ¼dÃ¼rlÃ¼kleri',
                    'critical': True
                },
                {
                    'name': 'SGK AnlaÅŸmalÄ± Kurumlar',
                    'script': 'fetch_sgk_anlasmali_kurumlar.py',
                    'description': 'SGK ile anlaÅŸmalÄ± tÃ¼m saÄŸlÄ±k hizmeti sunucularÄ±',
                    'critical': True
                },
                {
                    'name': 'Ãœniversite Hastaneleri',
                    'script': 'fetch_universite_hastaneleri.py',
                    'description': 'YÃ–K ve Ã¼niversite web sitelerinden',
                    'critical': False
                }
            ],
            'tier2': [
                {
                    'name': 'Ã–zel Hastane Zincirleri',
                    'script': 'fetch_ozel_hastane_zincirleri.py',
                    'description': 'AcÄ±badem, Medical Park, Memorial vb.',
                    'critical': False
                }
            ],
            'tier3': [
                {
                    'name': 'Google Places API',
                    'script': 'fetch_google_places.py',
                    'description': 'Google Maps POI verileri',
                    'critical': False
                }
            ]
        }
        
        self.execution_results = {
            'started_at': None,
            'completed_at': None,
            'tier1_results': {},
            'tier2_results': {},
            'tier3_results': {},
            'processing_result': None,
            'loading_result': None,
            'total_records': 0,
            'errors': []
        }

    def run_script(self, script_name: str) -> Dict:
        """Belirtilen script'i Ã§alÄ±ÅŸtÄ±rÄ±r ve sonucu dÃ¶ner"""
        script_path = self.scripts_dir / script_name
        
        if not script_path.exists():
            error_msg = f"Script bulunamadÄ±: {script_path}"
            self.logger.error(error_msg)
            return {
                'success': False,
                'error': error_msg,
                'duration': 0,
                'records': 0
            }
        
        self.logger.info(f"Ã‡alÄ±ÅŸtÄ±rÄ±lÄ±yor: {script_name}")
        start_time = time.time()
        
        try:
            # Run the script
            result = subprocess.run(
                [sys.executable, str(script_path)],
                capture_output=True,
                text=True,
                timeout=3600  # 1 hour timeout
            )
            
            duration = time.time() - start_time
            
            if result.returncode == 0:
                # Try to find and count records from output files
                records_count = self._count_records_from_latest_file(script_name)
                
                self.logger.info(f"âœ… {script_name} baÅŸarÄ±yla tamamlandÄ± ({duration:.1f}s, {records_count} kayÄ±t)")
                return {
                    'success': True,
                    'duration': duration,
                    'records': records_count,
                    'stdout': result.stdout,
                    'stderr': result.stderr
                }
            else:
                error_msg = f"Script baÅŸarÄ±sÄ±z: {script_name} (exit code: {result.returncode})"
                self.logger.error(f"âŒ {error_msg}")
                self.logger.error(f"STDERR: {result.stderr}")
                
                return {
                    'success': False,
                    'error': error_msg,
                    'duration': duration,
                    'records': 0,
                    'stdout': result.stdout,
                    'stderr': result.stderr
                }
                
        except subprocess.TimeoutExpired:
            duration = time.time() - start_time
            error_msg = f"Script timeout: {script_name} ({duration:.1f}s)"
            self.logger.error(f"â° {error_msg}")
            
            return {
                'success': False,
                'error': error_msg,
                'duration': duration,
                'records': 0
            }
        except Exception as e:
            duration = time.time() - start_time
            error_msg = f"Script Ã§alÄ±ÅŸtÄ±rma hatasÄ±: {script_name} - {str(e)}"
            self.logger.error(f"ðŸ’¥ {error_msg}")
            
            return {
                'success': False,
                'error': error_msg,
                'duration': duration,
                'records': 0
            }

    def _count_records_from_latest_file(self, script_name: str) -> int:
        """En son oluÅŸturulan veri dosyasÄ±ndan kayÄ±t sayÄ±sÄ±nÄ± okur"""
        try:
            # Find the most recent file that matches the script
            script_prefix = script_name.replace('fetch_', '').replace('.py', '')
            
            matching_files = list(self.raw_data_dir.glob(f"{script_prefix}*.json"))
            if not matching_files:
                return 0
            
            # Get the most recent file
            latest_file = max(matching_files, key=lambda f: f.stat().st_mtime)
            
            with open(latest_file, 'r', encoding='utf-8') as f:
                data = json.load(f)
                return data.get('toplam_kayit', 0)
                
        except Exception as e:
            self.logger.warning(f"KayÄ±t sayÄ±sÄ± okunamadÄ± {script_name}: {e}")
            return 0

    def run_tier(self, tier_name: str, sources: List[Dict]) -> Dict:
        """Belirtilen tier'daki tÃ¼m kaynaklarÄ± Ã§alÄ±ÅŸtÄ±rÄ±r"""
        self.logger.info(f"\nðŸš€ {tier_name.upper()} KAYNAKLARI BAÅžLATILIYOR...")
        
        tier_results = {}
        total_records = 0
        errors = []
        
        for source in sources:
            result = self.run_script(source['script'])
            tier_results[source['name']] = result
            
            if result['success']:
                total_records += result['records']
            else:
                errors.append(f"{source['name']}: {result.get('error', 'Bilinmeyen hata')}")
                
                # Critical source failure iÃ§in durumu kontrol et
                if source.get('critical', False):
                    self.logger.warning(f"âš ï¸  Kritik kaynak baÅŸarÄ±sÄ±z: {source['name']}")
        
        success_count = sum(1 for r in tier_results.values() if r['success'])
        total_count = len(sources)
        
        self.logger.info(f"ðŸ“Š {tier_name.upper()} SONUÃ‡LARI: {success_count}/{total_count} baÅŸarÄ±lÄ±, {total_records} toplam kayÄ±t")
        
        return {
            'success_count': success_count,
            'total_count': total_count,
            'total_records': total_records,
            'results': tier_results,
            'errors': errors
        }

    def run_data_processing(self) -> Dict:
        """Veri iÅŸleme script'ini Ã§alÄ±ÅŸtÄ±rÄ±r"""
        self.logger.info("\nðŸ”„ VERÄ° Ä°ÅžLEME BAÅžLATILIYOR...")
        
        process_script = 'process_data.py'
        result = self.run_script(process_script)
        
        if result['success']:
            self.logger.info("âœ… Veri iÅŸleme tamamlandÄ±")
        else:
            self.logger.error("âŒ Veri iÅŸleme baÅŸarÄ±sÄ±z")
        
        return result

    def run_data_loading(self) -> Dict:
        """Supabase veri yÃ¼kleme script'ini Ã§alÄ±ÅŸtÄ±rÄ±r"""
        self.logger.info("\nðŸ“¤ SUPABASE YÃœKLEME BAÅžLATILIYOR...")
        
        load_script = 'load_to_supabase.py'
        result = self.run_script(load_script)
        
        if result['success']:
            self.logger.info("âœ… Supabase yÃ¼kleme tamamlandÄ±")
        else:
            self.logger.error("âŒ Supabase yÃ¼kleme baÅŸarÄ±sÄ±z")
        
        return result

    def generate_report(self) -> str:
        """Pipeline Ã§alÄ±ÅŸma raporu oluÅŸturur"""
        report_lines = [
            "# TURSAKUR 2.0 Veri Pipeline Raporu",
            f"**Ã‡alÄ±ÅŸma Tarihi:** {self.execution_results['started_at']}",
            f"**Tamamlanma Tarihi:** {self.execution_results['completed_at']}",
            ""
        ]
        
        # Tier summaries
        for tier_name in ['tier1', 'tier2', 'tier3']:
            tier_key = f"{tier_name}_results"
            if tier_key in self.execution_results and self.execution_results[tier_key]:
                tier_data = self.execution_results[tier_key]
                report_lines.extend([
                    f"## {tier_name.upper()} SonuÃ§larÄ±",
                    f"- **BaÅŸarÄ±lÄ±:** {tier_data['success_count']}/{tier_data['total_count']}",
                    f"- **Toplam KayÄ±t:** {tier_data['total_records']:,}",
                    ""
                ])
                
                # Individual source results
                for source_name, result in tier_data['results'].items():
                    status = "âœ…" if result['success'] else "âŒ"
                    duration = result.get('duration', 0)
                    records = result.get('records', 0)
                    report_lines.append(f"  - {status} **{source_name}**: {records:,} kayÄ±t ({duration:.1f}s)")
                
                report_lines.append("")
        
        # Processing and Loading
        if self.execution_results.get('processing_result'):
            result = self.execution_results['processing_result']
            status = "âœ…" if result['success'] else "âŒ"
            report_lines.extend([
                "## Veri Ä°ÅŸleme",
                f"{status} Durum: {'BaÅŸarÄ±lÄ±' if result['success'] else 'BaÅŸarÄ±sÄ±z'}",
                f"SÃ¼re: {result.get('duration', 0):.1f} saniye",
                ""
            ])
        
        if self.execution_results.get('loading_result'):
            result = self.execution_results['loading_result']
            status = "âœ…" if result['success'] else "âŒ"
            report_lines.extend([
                "## Supabase YÃ¼kleme",
                f"{status} Durum: {'BaÅŸarÄ±lÄ±' if result['success'] else 'BaÅŸarÄ±sÄ±z'}",
                f"SÃ¼re: {result.get('duration', 0):.1f} saniye",
                ""
            ])
        
        # Summary
        total_records = sum(
            self.execution_results.get(f"{tier}_results", {}).get('total_records', 0)
            for tier in ['tier1', 'tier2', 'tier3']
        )
        
        report_lines.extend([
            "## Ã–zet",
            f"- **Toplam KayÄ±t:** {total_records:,}",
            f"- **Ã‡alÄ±ÅŸma SÃ¼resi:** {self._calculate_total_duration():.1f} saniye",
            ""
        ])
        
        # Errors
        all_errors = []
        for tier in ['tier1', 'tier2', 'tier3']:
            tier_data = self.execution_results.get(f"{tier}_results", {})
            all_errors.extend(tier_data.get('errors', []))
        
        if all_errors:
            report_lines.extend([
                "## Hatalar",
                *[f"- {error}" for error in all_errors],
                ""
            ])
        
        return "\n".join(report_lines)

    def _calculate_total_duration(self) -> float:
        """Toplam Ã§alÄ±ÅŸma sÃ¼resini hesaplar"""
        if self.execution_results['started_at'] and self.execution_results['completed_at']:
            start = datetime.fromisoformat(self.execution_results['started_at'])
            end = datetime.fromisoformat(self.execution_results['completed_at'])
            return (end - start).total_seconds()
        return 0.0

    def save_report(self, report_content: str):
        """Raporu dosyaya kaydeder"""
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        report_file = self.data_dir / f"pipeline_report_{timestamp}.md"
        
        with open(report_file, 'w', encoding='utf-8') as f:
            f.write(report_content)
        
        self.logger.info(f"ðŸ“„ Rapor kaydedildi: {report_file}")

    def run(self, run_tier1=True, run_tier2=True, run_tier3=True, run_processing=True, run_loading=True):
        """Ana pipeline'Ä± Ã§alÄ±ÅŸtÄ±rÄ±r"""
        self.execution_results['started_at'] = datetime.now(timezone.utc).isoformat()
        
        self.logger.info("ðŸŽ¯ TURSAKUR 2.0 VERÄ° PIPELINE BAÅžLATILIYOR...")
        self.logger.info("=" * 60)
        
        try:
            # Tier 1 - En YÃ¼ksek Ã–ncelik
            if run_tier1:
                self.execution_results['tier1_results'] = self.run_tier('tier1', self.data_sources['tier1'])
            
            # Tier 2 - DoÄŸrulama ve ZenginleÅŸtirme
            if run_tier2:
                self.execution_results['tier2_results'] = self.run_tier('tier2', self.data_sources['tier2'])
            
            # Tier 3 - KeÅŸif ve Ã‡apraz Referans
            if run_tier3:
                self.execution_results['tier3_results'] = self.run_tier('tier3', self.data_sources['tier3'])
            
            # Data Processing
            if run_processing:
                self.execution_results['processing_result'] = self.run_data_processing()
            
            # Data Loading
            if run_loading and self.execution_results.get('processing_result', {}).get('success', False):
                self.execution_results['loading_result'] = self.run_data_loading()
            
            self.execution_results['completed_at'] = datetime.now(timezone.utc).isoformat()
            
            # Generate and save report
            report = self.generate_report()
            self.save_report(report)
            
            self.logger.info("=" * 60)
            self.logger.info("ðŸŽ‰ TURSAKUR 2.0 VERÄ° PIPELINE TAMAMLANDI!")
            
            return True
            
        except Exception as e:
            self.execution_results['completed_at'] = datetime.now(timezone.utc).isoformat()
            self.logger.error(f"ðŸ’¥ Pipeline genel hatasÄ±: {e}")
            return False

def main():
    """Ana fonksiyon"""
    import argparse
    
    parser = argparse.ArgumentParser(description='TURSAKUR 2.0 Veri Pipeline')
    parser.add_argument('--skip-tier1', action='store_true', help='Tier 1 kaynaklarÄ±nÄ± atla')
    parser.add_argument('--skip-tier2', action='store_true', help='Tier 2 kaynaklarÄ±nÄ± atla')
    parser.add_argument('--skip-tier3', action='store_true', help='Tier 3 kaynaklarÄ±nÄ± atla')
    parser.add_argument('--skip-processing', action='store_true', help='Veri iÅŸlemeyi atla')
    parser.add_argument('--skip-loading', action='store_true', help='Supabase yÃ¼klemeyi atla')
    
    args = parser.parse_args()
    
    orchestrator = DataPipelineOrchestrator()
    success = orchestrator.run(
        run_tier1=not args.skip_tier1,
        run_tier2=not args.skip_tier2,
        run_tier3=not args.skip_tier3,
        run_processing=not args.skip_processing,
        run_loading=not args.skip_loading
    )
    
    return 0 if success else 1

if __name__ == "__main__":
    exit(main())
