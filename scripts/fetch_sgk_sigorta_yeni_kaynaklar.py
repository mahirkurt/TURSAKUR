#!/usr/bin/env python3
"""
SGK SHS ve Sigorta Åirketleri Yeni Veri KaynaklarÄ± KeÅŸif Scripti
==============================================================

Yeni keÅŸfedilen SGK ve sigorta ÅŸirketi veri kaynaklarÄ±:
1. E-Devlet SGK borÃ§ sorgulama sistemleri
2. Sigorta ÅŸirketlerinin anlaÅŸmalÄ± saÄŸlÄ±k kuruluÅŸlarÄ± listeleri
3. Hekim mesleki sorumluluk sigortasÄ± veritabanlarÄ±
4. Ã–zel sigorta ÅŸirketlerinin panel sistemleri
5. MHRS sistemine entegre saÄŸlÄ±k kuruluÅŸlarÄ±
"""

import requests
import json
import os
import logging
from datetime import datetime
from typing import List, Dict, Any, Optional
from bs4 import BeautifulSoup
import re

logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

class SGKSigortaYeniKaynaklar:
    """SGK ve sigorta ÅŸirketleri iÃ§in yeni veri kaynaklarÄ±nÄ± Ã§eken sÄ±nÄ±f."""
    
    def __init__(self):
        self.session = requests.Session()
        self.session.headers.update({
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
        })
        
        # BÃ¼yÃ¼k sigorta ÅŸirketleri ve anlaÅŸmalÄ± kuruluÅŸ listeleri
        self.sigorta_sirketleri = {
            'aksigorta': {
                'base_url': 'https://www.aksigorta.com.tr',
                'anlasmalÄ±_url': '/saglik/anlasmalÄ±-saglik-kuruluslari',
                'name': 'Ak Sigorta'
            },
            'allianz': {
                'base_url': 'https://www.allianz.com.tr',
                'anlasmalÄ±_url': '/tr_TR/bireysel/saglik-sigortasi/anlasmalÄ±-kurumlar.html',
                'name': 'Allianz Sigorta'
            },
            'sompo': {
                'base_url': 'https://www.somposigorta.com.tr',
                'anlasmalÄ±_url': '/anlasmalÄ±-saglik-kuruluslari',
                'name': 'Sompo Sigorta'
            },
            'anadolu': {
                'base_url': 'https://www.anadolusigorta.com.tr',
                'anlasmalÄ±_url': '/saglik-sigortasi/anlasmalÄ±-saglik-kuruluslari',
                'name': 'Anadolu Sigorta'
            },
            'mapfre': {
                'base_url': 'https://www.mapfreassist.com.tr',
                'anlasmalÄ±_url': '/saglik-kuruluslari',
                'name': 'Mapfre Sigorta'
            },
            'gunes': {
                'base_url': 'https://www.gunessigortasi.com.tr',
                'anlasmalÄ±_url': '/saglik/anlasmalÄ±-hastaneler',
                'name': 'GÃ¼neÅŸ Sigorta'
            },
            'euroins': {
                'base_url': 'https://www.euroins.com.tr',
                'anlasmalÄ±_url': '/saglik-sigortasi/anlasmalÄ±-kurumlar',
                'name': 'Euroins Sigorta'
            }
        }
        
        # Alternatif SGK veri kaynaklarÄ±
        self.sgk_alternatif_kaynaklar = {
            'e_devlet_sms': 'https://www.turkiye.gov.tr/sgk-borcu-sorgulama',
            'mhrs_entegrasyon': 'https://www.mhrs.gov.tr',
            'tip_merkezi_birlikleri': [
                'https://www.tobb.org.tr',  # TOBB saÄŸlÄ±k sektÃ¶rÃ¼
                'https://www.iso.org.tr',   # Ä°SO saÄŸlÄ±k komisyonu
            ]
        }
        
        # SaÄŸlÄ±k birlik ve dernekleri
        self.saglik_birlikleri = {
            'ttb': 'https://www.ttb.org.tr',  # TÃ¼rk Tabipler BirliÄŸi
            'sted': 'https://www.sted.org.tr',  # SaÄŸlÄ±k Turizmini GeliÅŸtirme DerneÄŸi
            'tusev': 'https://www.tusev.org.tr',  # TÃ¼rkiye ÃœÃ§Ã¼ncÃ¼ SektÃ¶r VakfÄ±
            'ohsad': 'http://www.ohsad.org',  # Ã–zel Hastaneler ve SaÄŸlÄ±k KuruluÅŸlarÄ± DerneÄŸi
        }
        
        self.data_dir = os.path.join(os.path.dirname(__file__), '..', 'data', 'raw')
        os.makedirs(self.data_dir, exist_ok=True)
    
    def fetch_sigorta_anlasmalÄ±_kurumlar(self, sigorta_key: str, sigorta_info: Dict) -> List[Dict]:
        """Bir sigorta ÅŸirketinin anlaÅŸmalÄ± saÄŸlÄ±k kuruluÅŸlarÄ±nÄ± Ã§ek"""
        institutions = []
        
        try:
            company_name = sigorta_info['name']
            logger.info(f"Sigorta ÅŸirketi taranÄ±yor: {company_name}")
            
            # FarklÄ± URL kombinasyonlarÄ±nÄ± dene
            possible_urls = [
                sigorta_info['base_url'] + sigorta_info['anlasmalÄ±_url'],
                sigorta_info['base_url'] + '/anlasmalÄ±-kurumlar',
                sigorta_info['base_url'] + '/saglik/hastaneler',
                sigorta_info['base_url'] + '/saglik-kuruluslari',
                sigorta_info['base_url'] + '/provider-network',
                sigorta_info['base_url'] + '/health-institutions'
            ]
            
            for url in possible_urls:
                try:
                    response = self.session.get(url, timeout=20)
                    if response.status_code == 200:
                        institutions.extend(self._parse_sigorta_page(response.text, company_name, url))
                        break  # BaÅŸarÄ±lÄ± olursa diÄŸer URL'leri deneme
                except Exception:
                    continue
            
            if institutions:
                logger.info(f"âœ… {company_name}: {len(institutions)} anlaÅŸmalÄ± kurum bulundu")
            
        except Exception as e:
            logger.warning(f"Sigorta ÅŸirketi hatasÄ± {sigorta_key}: {e}")
        
        return institutions
    
    def _parse_sigorta_page(self, html_content: str, company_name: str, url: str) -> List[Dict]:
        """Sigorta ÅŸirketi sayfasÄ±nÄ± parse et"""
        institutions = []
        
        try:
            soup = BeautifulSoup(html_content, 'html.parser')
            
            # FarklÄ± yapÄ±larda kurum isimlerini ara
            search_patterns = [
                {'tag': 'div', 'class_contains': 'hospital'},
                {'tag': 'div', 'class_contains': 'kurum'},
                {'tag': 'li', 'class_contains': 'provider'},
                {'tag': 'td', 'text_contains': 'hastane'},
                {'tag': 'span', 'class_contains': 'institution'}
            ]
            
            for pattern in search_patterns:
                elements = soup.find_all(pattern['tag'])
                
                for element in elements:
                    text = element.get_text(strip=True)
                    
                    # Hastane/kurum ismi pattern'lerini kontrol et
                    if self._is_health_institution(text):
                        institution = {
                            'kurum_adi': self._clean_institution_name(text),
                            'kurum_tipi': self._determine_institution_type(text),
                            'veri_kaynagi': f'{company_name} AnlaÅŸmalÄ± KuruluÅŸlar',
                            'sigorta_sirket': company_name,
                            'kaynak_url': url,
                            'son_guncelleme': datetime.now().strftime('%Y-%m-%d')
                        }
                        
                        # Åehir bilgisini Ã§Ä±karmaya Ã§alÄ±ÅŸ
                        city = self._extract_city_from_text(text)
                        if city:
                            institution['il_adi'] = city
                        
                        institutions.append(institution)
            
            # Excel/PDF linklerini de kontrol et
            doc_links = soup.find_all('a', href=re.compile(r'\.(xlsx?|pdf)$', re.I))
            for link in doc_links:
                href = link.get('href')
                link_text = link.get_text(strip=True)
                
                if any(keyword in link_text.lower() for keyword in ['liste', 'kurum', 'hastane', 'anlasmalÄ±']):
                    if not href.startswith('http'):
                        href = url.rsplit('/', 1)[0] + '/' + href.lstrip('/')
                    
                    logger.info(f"âœ“ {company_name} dosyasÄ± bulundu: {link_text} - {href}")
                    # Bu dosyalarÄ± parse edebiliriz
                    
        except Exception as e:
            logger.error(f"Sigorta sayfa parse hatasÄ±: {e}")
        
        return institutions
    
    def _is_health_institution(self, text: str) -> bool:
        """Metnin saÄŸlÄ±k kurumu olup olmadÄ±ÄŸÄ±nÄ± kontrol et"""
        text_lower = text.lower()
        health_keywords = [
            'hastane', 'hospital', 'tÄ±p merkezi', 'medical', 'saÄŸlÄ±k', 'health',
            'poliklinik', 'clinic', 'diyaliz', 'dialysis', 'laboratuvar', 'lab',
            'eczane', 'pharmacy', 'diÅŸ', 'dental', 'gÃ¶z', 'eye', 'kalp', 'heart'
        ]
        
        return any(keyword in text_lower for keyword in health_keywords) and len(text) > 5
    
    def _clean_institution_name(self, raw_name: str) -> str:
        """Kurum adÄ±nÄ± temizle"""
        clean_name = raw_name.strip()
        clean_name = re.sub(r'\s+', ' ', clean_name)
        clean_name = re.sub(r'[^\w\s-.]', '', clean_name)
        
        # Ã‡ok kÄ±sa veya geÃ§ersiz isimleri filtrele
        if len(clean_name) < 5:
            return ''
        
        return clean_name.title()
    
    def _determine_institution_type(self, text: str) -> str:
        """Kurum tÃ¼rÃ¼nÃ¼ belirle"""
        text_lower = text.lower()
        
        if 'Ã¼niversite' in text_lower:
            return 'Ãœniversite Hastanesi'
        elif 'Ã¶zel' in text_lower and 'hastane' in text_lower:
            return 'Ã–zel Hastane'
        elif 'devlet' in text_lower or 'kamu' in text_lower:
            return 'Devlet Hastanesi'
        elif 'tÄ±p merkezi' in text_lower or 'medical' in text_lower:
            return 'TÄ±p Merkezi'
        elif 'poliklinik' in text_lower:
            return 'Poliklinik'
        elif 'diyaliz' in text_lower:
            return 'Diyaliz Merkezi'
        elif 'laboratuvar' in text_lower:
            return 'Laboratuvar'
        elif 'eczane' in text_lower:
            return 'Eczane'
        else:
            return 'SaÄŸlÄ±k Kurumu'
    
    def _extract_city_from_text(self, text: str) -> Optional[str]:
        """Metinden ÅŸehir adÄ±nÄ± Ã§Ä±kar"""
        major_cities = [
            'Ä°stanbul', 'Ankara', 'Ä°zmir', 'Bursa', 'Antalya', 'Adana',
            'Konya', 'Gaziantep', 'Kayseri', 'EskiÅŸehir', 'Mersin',
            'Kocaeli', 'Trabzon', 'Samsun', 'DiyarbakÄ±r', 'Malatya'
        ]
        
        text_lower = text.lower()
        for city in major_cities:
            if city.lower() in text_lower:
                return city
        
        return None
    
    def fetch_saglik_birlikleri_data(self) -> List[Dict]:
        """SaÄŸlÄ±k birlik ve derneklerinden veri Ã§ek"""
        all_data = []
        
        for birlik_key, birlik_url in self.saglik_birlikleri.items():
            try:
                logger.info(f"SaÄŸlÄ±k birliÄŸi taranÄ±yor: {birlik_key}")
                
                response = self.session.get(birlik_url, timeout=20)
                response.raise_for_status()
                
                soup = BeautifulSoup(response.text, 'html.parser')
                
                # Ãœye listesi, kurum dizini gibi bÃ¶lÃ¼mleri ara
                member_links = soup.find_all('a', href=re.compile(r'(uye|member|kurum|hastane)', re.I))
                
                for link in member_links:
                    href = link.get('href')
                    text = link.get_text(strip=True)
                    
                    if 'liste' in text.lower() or 'directory' in text.lower():
                        if not href.startswith('http'):
                            href = birlik_url + href
                        
                        logger.info(f"âœ“ {birlik_key} Ã¼ye listesi bulundu: {text}")
                        # Bu linkleri takip edip parse edebiliriz
                
            except Exception as e:
                logger.warning(f"SaÄŸlÄ±k birliÄŸi hatasÄ± {birlik_key}: {e}")
        
        return all_data
    
    def fetch_all_sgk_sigorta_sources(self) -> List[Dict]:
        """TÃ¼m SGK ve sigorta veri kaynaklarÄ±nÄ± Ã§ek"""
        all_institutions = []
        
        logger.info("ğŸ›ï¸ SGK ve sigorta ÅŸirketleri yeni veri kaynaklarÄ± taranÄ±yor...")
        
        # 1. Sigorta ÅŸirketlerinin anlaÅŸmalÄ± kuruluÅŸlarÄ±
        for sigorta_key, sigorta_info in self.sigorta_sirketleri.items():
            institutions = self.fetch_sigorta_anlasmalÄ±_kurumlar(sigorta_key, sigorta_info)
            all_institutions.extend(institutions)
        
        logger.info(f"âœ… Sigorta ÅŸirketleri: {len(all_institutions)} kurum")
        
        # 2. SaÄŸlÄ±k birlik ve dernekleri
        birlik_data = self.fetch_saglik_birlikleri_data()
        all_institutions.extend(birlik_data)
        logger.info(f"âœ… SaÄŸlÄ±k birlikleri: {len(birlik_data)} kurum")
        
        # DuplikatlarÄ± temizle
        unique_institutions = []
        seen_names = set()
        
        for institution in all_institutions:
            name_key = institution['kurum_adi'].lower().strip()
            if name_key not in seen_names and len(name_key) > 5:
                seen_names.add(name_key)
                unique_institutions.append(institution)
        
        logger.info(f"ğŸ¯ Toplam benzersiz SGK/Sigorta kurumu: {len(unique_institutions)}")
        return unique_institutions
    
    def save_data(self, institutions: List[Dict]):
        """Verileri kaydet"""
        json_file = os.path.join(self.data_dir, 'sgk_sigorta_yeni_kaynaklar.json')
        
        with open(json_file, 'w', encoding='utf-8') as f:
            json.dump(institutions, f, ensure_ascii=False, indent=2)
        
        logger.info(f"ğŸ’¾ SGK/Sigorta verileri kaydedildi: {json_file}")

def main():
    """Ana fonksiyon"""
    logger.info("SGK ve sigorta ÅŸirketleri yeni veri kaynaklarÄ± keÅŸfi baÅŸlÄ±yor...")
    
    fetcher = SGKSigortaYeniKaynaklar()
    
    try:
        institutions = fetcher.fetch_all_sgk_sigorta_sources()
        
        if institutions:
            fetcher.save_data(institutions)
            
            # Ä°statistikler
            companies = {}
            types = {}
            
            for institution in institutions:
                company = institution.get('sigorta_sirket', 'Bilinmiyor')
                inst_type = institution.get('kurum_tipi', 'Bilinmiyor')
                
                companies[company] = companies.get(company, 0) + 1
                types[inst_type] = types.get(inst_type, 0) + 1
            
            logger.info("ğŸ¢ Sigorta ÅŸirketi bazlÄ± daÄŸÄ±lÄ±m:")
            for company, count in sorted(companies.items(), key=lambda x: x[1], reverse=True):
                logger.info(f"   - {company}: {count}")
            
            logger.info("ğŸ¥ Kurum tÃ¼rÃ¼ bazlÄ± daÄŸÄ±lÄ±m:")
            for inst_type, count in sorted(types.items(), key=lambda x: x[1], reverse=True):
                logger.info(f"   - {inst_type}: {count}")
                
            logger.info("âœ… SGK ve sigorta ÅŸirketleri yeni kaynaklar iÅŸlemi tamamlandÄ±!")
        else:
            logger.warning("âŒ HiÃ§ SGK/sigorta kurumu bulunamadÄ±!")
            
    except Exception as e:
        logger.error(f"âŒ Ä°ÅŸlem baÅŸarÄ±sÄ±z: {e}")

if __name__ == "__main__":
    main()
